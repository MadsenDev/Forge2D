use std::{collections::HashMap, fs};

use anyhow::{anyhow, Result};
use bytemuck::{Pod, Zeroable};
use wgpu::util::DeviceExt;
use wgpu::{
    vertex_attr_array, AddressMode, BindGroupDescriptor, BindGroupEntry, BindGroupLayout,
    BindGroupLayoutDescriptor, BindGroupLayoutEntry, BindingResource, BindingType, Buffer,
    BufferBindingType, BufferUsages, ColorTargetState, ColorWrites, CommandEncoder,
    CommandEncoderDescriptor, CompositeAlphaMode, DeviceDescriptor, Extent3d, FilterMode,
    FragmentState, Instance, LoadOp, MultisampleState, Operations, Origin3d,
    PipelineLayoutDescriptor, PresentMode, PrimitiveState, RenderPassColorAttachment,
    RenderPassDescriptor, RenderPipeline, RenderPipelineDescriptor, RequestAdapterOptions, Sampler,
    SamplerBindingType, SamplerDescriptor, ShaderModuleDescriptor, ShaderSource,
    SurfaceConfiguration, TexelCopyBufferLayout, TexelCopyTextureInfo, Texture, TextureAspect,
    TextureDescriptor, TextureDimension, TextureFormat, TextureSampleType, TextureUsages,
    TextureView, TextureViewDescriptor, TextureViewDimension, VertexState,
};
use winit::{dpi::PhysicalSize, window::Window};

use crate::{
    math::{Camera2D, Transform2D, Vec2},
    render::light::PointLight,
    render::particles::ParticleSystem,
    render::sprite::{Sprite, TextureHandle},
    render::text::{FontHandle, TextRenderer},
};
use glam::{Mat4, Vec3};
use glyphon::{
    Attrs, Buffer as GlyphonBuffer, Cache, Color, Family, Metrics, Shaping, TextArea,
    TextAtlas, TextRenderer as GlyphonTextRenderer, Viewport,
};

/// Queued sprite draw command (batched rendering)
struct SpriteDrawCommand {
    uniform_offset: u64,
    texture_handle: TextureHandle, // Store texture handle, look up bind group when flushing
}

/// Wrapper around wgpu surface/device setup and simple frame management.
pub struct Renderer<'window> {
    backend: WgpuBackend<'window>,
}

impl<'window> Renderer<'window> {
    pub fn new(window: &'window Window, vsync: bool) -> Result<Self> {
        let backend = WgpuBackend::new(window, vsync)?;
        Ok(Self { backend })
    }

    pub fn resize(&mut self, new_size: PhysicalSize<u32>) {
        self.backend.resize(new_size);
    }

    pub fn begin_frame(&mut self) -> Result<Frame> {
        self.backend.begin_frame()
    }

    pub fn clear(&mut self, frame: &mut Frame, color: [f32; 4]) -> Result<()> {
        self.backend.clear(frame, color)
    }

    pub fn draw_sprite(
        &mut self,
        frame: &mut Frame,
        sprite: &Sprite,
        camera: &Camera2D,
    ) -> Result<()> {
        self.backend.draw_sprite(frame, sprite, camera)
    }

    /// Draw a section of a texture (useful for spritesheets).
    /// * `uv_rect`: Normalized UV coordinates [x, y, w, h].
    ///   - x, y: Top-left corner (0.0 to 1.0)
    ///   - w, h: Width and Height (0.0 to 1.0)
    ///   - If None, renders the full texture.
    pub fn draw_texture_region(
        &mut self,
        frame: &mut Frame,
        texture: TextureHandle,
        uv_rect: Option<[f32; 4]>,
        transform: &crate::math::Transform2D,
        tint: [f32; 4],
        is_occluder: bool,
        camera: &Camera2D,
    ) -> Result<()> {
        self.backend.draw_texture_region(
            frame,
            texture,
            uv_rect,
            transform,
            tint,
            is_occluder,
            camera
        )
    }

    /// Draw a tilemap efficiently (batched rendering).
    pub fn draw_tilemap(
        &mut self,
        frame: &mut Frame,
        tilemap: &crate::render::Tilemap,
        camera: &Camera2D,
    ) -> Result<()> {
        self.backend.draw_tilemap(frame, tilemap, camera)
    }

    pub fn end_frame(&mut self, frame: Frame) -> Result<()> {
        self.backend.end_frame(frame)
    }

    pub fn load_texture_from_file(&mut self, path: &str) -> Result<TextureHandle> {
        self.backend.load_texture_from_file(path)
    }

    pub fn load_texture_from_bytes(&mut self, bytes: &[u8]) -> Result<TextureHandle> {
        self.backend.load_texture_from_bytes(bytes)
    }

    /// Load a texture from raw RGBA8 data (no PNG decoding).
    ///
    /// This is useful for procedurally generated textures or tests.
    /// `data` must be `width * height * 4` bytes in RGBA8 format.
    pub fn load_texture_from_rgba(
        &mut self,
        data: &[u8],
        width: u32,
        height: u32,
    ) -> Result<TextureHandle> {
        // Default to false (sprite texture) for backward compatibility
        self.backend
            .load_texture_from_rgba(data, width, height, false)
    }

    pub fn texture_size(&self, handle: TextureHandle) -> Option<(u32, u32)> {
        self.backend.texture_size(handle)
    }

    pub fn surface_size(&self) -> (u32, u32) {
        self.backend.surface_size()
    }

    /// Load a font from bytes (TTF/OTF format).
    pub fn load_font_from_bytes(&mut self, bytes: &[u8]) -> Result<FontHandle> {
        self.backend.load_font_from_bytes(bytes)
    }

    /// Rasterize all glyphs needed for a text string.
    /// Call this before draw_text() to ensure glyphs are cached.
    pub fn rasterize_text_glyphs(&mut self, text: &str, font: FontHandle, size: f32) -> Result<()> {
        self.backend.ensure_glyphs_rasterized(text, font, size)
    }

    /// Draw text at the specified position in world coordinates.
    ///
    /// # Arguments
    /// * `frame` - The current frame being rendered
    /// * `text` - The text string to render
    /// * `font` - The font handle to use
    /// * `size` - Font size in pixels
    /// * `position` - World position (bottom-left of first character)
    /// * `color` - RGBA color tint
    /// * `camera` - Camera for view projection
    ///
    /// # Note
    /// All glyphs must be pre-rasterized using `rasterize_text_glyphs()` before calling this.
    pub fn draw_text(
        &mut self,
        frame: &mut Frame,
        text: &str,
        font: FontHandle,
        size: f32,
        position: Vec2,
        color: [f32; 4],
        camera: &Camera2D,
    ) -> Result<()> {
        self.backend
            .draw_text(frame, text, font, size, position, color, camera)
    }

    /// Measure the width of text without drawing it.
    /// This is useful for accurate text alignment in HUD elements.
    pub fn measure_text_width(&mut self, text: &str, font: FontHandle, size: f32) -> Result<f32> {
        self.backend.measure_text_width(text, font, size)
    }

    /// Draw a filled polygon from a list of points.
    /// Points should be in world coordinates and will be transformed by the camera.
    pub fn draw_polygon(
        &mut self,
        frame: &mut Frame,
        points: &[Vec2],
        color: [f32; 4],
        camera: &Camera2D,
    ) -> Result<()> {
        self.backend.draw_polygon(frame, points, color, camera, true)
    }

    /// Draw a filled polygon that does not occlude light.
    pub fn draw_polygon_no_occlusion(
        &mut self,
        frame: &mut Frame,
        points: &[Vec2],
        color: [f32; 4],
        camera: &Camera2D,
    ) -> Result<()> {
        self.backend.draw_polygon(frame, points, color, camera, false)
    }

    /// Draw a filled circle.
    /// Center and radius are in world coordinates.
    pub fn draw_circle(
        &mut self,
        frame: &mut Frame,
        center: Vec2,
        radius: f32,
        color: [f32; 4],
        camera: &Camera2D,
    ) -> Result<()> {
        self.backend
            .draw_circle(frame, center, radius, color, camera)
    }

    /// Draw a point light (emits light in all directions from a position).
    /// Lights are rendered with additive blending after sprites.
    pub fn draw_point_light(
        &mut self,
        frame: &mut Frame,
        light: &PointLight,
        camera: &Camera2D,
    ) -> Result<()> {
        self.backend.draw_point_light(frame, light, camera)
    }

    /// Draw all particles from a particle system.
    /// Particles are rendered as sprites, so they can use textures or be simple colored quads.
    pub fn draw_particles(
        &mut self,
        frame: &mut Frame,
        particle_system: &ParticleSystem,
        camera: &Camera2D,
        default_texture: Option<TextureHandle>,
    ) -> Result<()> {
        for emitter in particle_system.emitters() {
            let texture = emitter.texture().or(default_texture);
            
            for particle in emitter.particles() {
                if !particle.is_alive() {
                    continue;
                }

                // Create a sprite for this particle
                let mut sprite = if let Some(tex) = texture {
                    Sprite::new(tex)
                } else {
                    // If no texture, we'll render as a colored quad
                    // For now, use a 1x1 white texture if available, or skip
                    // TODO: Add support for rendering particles as colored quads
                    continue;
                };

                sprite.transform.position = particle.position;
                sprite.transform.scale = particle.size;
                sprite.transform.rotation = particle.rotation;
                sprite.tint = particle.color;

                self.draw_sprite(frame, &sprite, camera)?;
            }
        }
        Ok(())
    }
}

pub struct Frame {
    surface_texture: Option<wgpu::SurfaceTexture>,
    view: TextureView,
    encoder: Option<CommandEncoder>,
    sprite_draws: Vec<SpriteDrawCommand>, // Queue of sprite draws for batching
    light_draws: Vec<LightDrawCommand>,   // Queue of light draws for batching
    // Render targets for lighting
    scene_texture: Option<Texture>,
    scene_texture_view: Option<TextureView>,
    occlusion_texture: Option<Texture>, // New occlusion target
    occlusion_texture_view: Option<TextureView>,
    light_map_texture: Option<Texture>,
    light_map_texture_view: Option<TextureView>,
    scene_cleared: bool, // Track if scene texture has been cleared this frame
}

impl Drop for Frame {
    fn drop(&mut self) {
        // If frame wasn't properly ended, we still need to present the surface texture
        // to avoid leaking resources. The encoder will be dropped automatically.
        if let Some(surface_texture) = self.surface_texture.take() {
            surface_texture.present();
        }
    }
}

struct TextureEntry {
    /// The underlying GPU texture. Must be kept alive for the view/sampler to be valid.
    texture: Texture,
    view: TextureView,
    sampler: Sampler,
    size: (u32, u32),
}

struct SpritePipeline {
    pipeline: RenderPipeline,
    vertex_buffer: Buffer,
    uniform_buffer: Buffer,
    bind_group_layout: BindGroupLayout,
    #[allow(dead_code)]
    uniform_buffer_size: u64,
    uniform_alignment: u64,
}

// Maximum number of sprites we can draw per frame
// Increased to 2048 sprites (512KB buffer) for better performance with large scenes
const MAX_SPRITES_PER_FRAME: usize = 2048;
const UNIFORM_BUFFER_SIZE: u64 = MAX_SPRITES_PER_FRAME as u64 * 512; // Increased for larger uniform struct

struct WgpuBackend<'window> {
    surface: wgpu::Surface<'window>,
    device: wgpu::Device,
    queue: wgpu::Queue,
    surface_config: SurfaceConfiguration,
    present_mode: PresentMode,
    sprite_pipeline: SpritePipeline,
    shape_pipeline: ShapePipeline,
    light_pipeline: LightPipeline,
    composite_pipeline: CompositePipeline,
    textures: HashMap<TextureHandle, TextureEntry>,
    light_uniform_write_offset: u64,
    next_texture_id: u32,
    uniform_write_offset: u64, // Current offset for writing uniforms
    bind_group_cache: HashMap<(TextureHandle, u64), wgpu::BindGroup>, // Cache bind groups per (texture, offset)
    text_renderer: TextRenderer,
}

#[repr(C)]
#[derive(Clone, Copy, Pod, Zeroable)]
struct SpriteVertex {
    position: [f32; 2],
    uv: [f32; 2],
}

#[repr(C)]
#[derive(Clone, Copy, Pod, Zeroable)]
struct SpriteUniforms {
    mvp: [[f32; 4]; 4],
    color: [f32; 4],
    uv_offset: [f32; 2],
    uv_scale: [f32; 2],
    is_occluder: f32,
    _pad: [f32; 3],
}

#[repr(C)]
#[derive(Clone, Copy, Pod, Zeroable)]
struct ShapeUniforms {
    mvp: [[f32; 4]; 4],
    color: [f32; 4],
    is_occluder: f32, // Added
    _pad: [f32; 3], // 4 + 12 = 16 bytes alignment
}

#[repr(C)]
#[derive(Clone, Copy, Pod, Zeroable)]
struct ShapeVertex {
    position: [f32; 2],
}

struct ShapePipeline {
    pipeline: RenderPipeline,
    bind_group_layout: BindGroupLayout,
    uniform_buffer: Buffer,
    uniform_alignment: u64,
}

#[repr(C, align(16))]
#[derive(Clone, Copy)]
struct LightUniforms {
    position: [f32; 2],
    _pad1: [f32; 2], // Padding to align color to 16 bytes
    color: [f32; 3],
    intensity: f32,
    radius: f32,
    falloff: f32,
    direction: [f32; 2], // Spotlight direction (normalized), or [0,0] for point light
    angle: f32,          // Spotlight angle (cos of half-angle), or 0 for point light
    _pad2: f32,          // Padding to align screen_size to 8 bytes
    screen_size: [f32; 2], // Screen size for shadow mapping
    // No padding needed here: 56 + 8 = 64 bytes, which is 16-byte aligned
    view_proj: [[f32; 4]; 4], // View-projection matrix for shadow mapping
    mvp: [[f32; 4]; 4],
}

struct LightPipeline {
    pipeline: RenderPipeline,
    bind_group_layout: BindGroupLayout,
    uniform_buffer: Buffer,
    uniform_alignment: u64,
    vertex_buffer: Buffer,
}

struct CompositePipeline {
    pipeline: RenderPipeline,
    bind_group_layout: BindGroupLayout,
    vertex_buffer: Buffer,
}

/// Queued light draw command
struct LightDrawCommand {
    uniform_offset: u64,
}

const SPRITE_VERTICES: [SpriteVertex; 6] = [
    SpriteVertex {
        position: [-0.5, -0.5],
        uv: [0.0, 0.0], // Top-left (WebGPU convention)
    },
    SpriteVertex {
        position: [0.5, -0.5],
        uv: [1.0, 0.0], // Top-right
    },
    SpriteVertex {
        position: [0.5, 0.5],
        uv: [1.0, 1.0], // Bottom-right
    },
    SpriteVertex {
        position: [-0.5, -0.5],
        uv: [0.0, 0.0], // Top-left
    },
    SpriteVertex {
        position: [0.5, 0.5],
        uv: [1.0, 1.0], // Bottom-right
    },
    SpriteVertex {
        position: [-0.5, 0.5],
        uv: [0.0, 1.0], // Bottom-left
    },
];

impl<'window> WgpuBackend<'window> {
    fn new(window: &'window Window, vsync: bool) -> Result<Self> {
        let instance = Instance::default();
        let surface = instance.create_surface(window)?;

        let adapter = pollster::block_on(instance.request_adapter(&RequestAdapterOptions {
            power_preference: wgpu::PowerPreference::HighPerformance,
            compatible_surface: Some(&surface),
            force_fallback_adapter: false,
        }))?;

        let (device, queue) = pollster::block_on(adapter.request_device(&DeviceDescriptor {
                label: Some("forge2d-device"),
                required_features: wgpu::Features::empty(),
                required_limits: wgpu::Limits::default(),
                experimental_features: Default::default(),
                memory_hints: Default::default(),
                trace: wgpu::Trace::Off,
        }))?;

        let size = window.inner_size();
        let capabilities = surface.get_capabilities(&adapter);
        let format = capabilities
            .formats
            .iter()
            .copied()
            .find(|format| format.is_srgb())
            .unwrap_or(capabilities.formats[0]);

        let present_mode = choose_present_mode(&capabilities.present_modes, vsync);
        let alpha_mode = choose_alpha_mode(&capabilities.alpha_modes);

        let surface_config = SurfaceConfiguration {
            usage: TextureUsages::RENDER_ATTACHMENT,
            format,
            width: size.width.max(1),
            height: size.height.max(1),
            present_mode,
            alpha_mode,
            view_formats: vec![],
            desired_maximum_frame_latency: 2,
        };
        surface.configure(&device, &surface_config);

        let sprite_pipeline = create_sprite_pipeline(&device, format);
        let shape_pipeline = create_shape_pipeline(&device, format);
        let light_pipeline = create_light_pipeline(&device, format);
        let composite_pipeline = create_composite_pipeline(&device, format);

        Ok(Self {
            surface,
            device,
            queue,
            surface_config,
            present_mode,
            sprite_pipeline,
            shape_pipeline,
            light_pipeline,
            composite_pipeline,
            textures: HashMap::new(),
            next_texture_id: 1,
            uniform_write_offset: 0,
            light_uniform_write_offset: 0,
            bind_group_cache: HashMap::new(),
            text_renderer: TextRenderer::new(),
        })
    }

    fn ensure_text_components_initialized(&mut self) -> Result<()> {
        // Initialize glyphon components if not already initialized
        if self.text_renderer.text_atlas_mut().is_none() {
            let (_width, _height) = (self.surface_config.width, self.surface_config.height);
            
            // Initialize GPU Cache first (needed for TextAtlas)
            let gpu_cache = Cache::new(&self.device);
            
            // Initialize TextAtlas - try the API based on compiler errors
            let mut text_atlas = TextAtlas::new(&self.device, &self.queue, &gpu_cache, self.surface_config.format);
            
            // Initialize GlyphonTextRenderer
            let text_renderer = GlyphonTextRenderer::new(&mut text_atlas, &self.device, wgpu::MultisampleState::default(), None);
            
            // Initialize Viewport - API: new(device, cache)
            let viewport = Viewport::new(&self.device, &gpu_cache);
            
            *self.text_renderer.text_atlas_mut() = Some(text_atlas);
            *self.text_renderer.text_renderer_mut() = Some(text_renderer);
            *self.text_renderer.viewport_mut() = Some(viewport);
            *self.text_renderer.gpu_cache_mut() = Some(gpu_cache);
        }
        Ok(())
    }

    fn resize(&mut self, new_size: PhysicalSize<u32>) {
        if new_size.width == 0 || new_size.height == 0 {
            return;
        }

        self.surface_config.width = new_size.width;
        self.surface_config.height = new_size.height;
        self.surface_config.present_mode = self.present_mode;
        self.surface.configure(&self.device, &self.surface_config);
    }

    fn begin_frame(&mut self) -> Result<Frame> {
        // Reset uniform buffer offset at the start of each frame
        self.uniform_write_offset = 0;
        self.light_uniform_write_offset = 0;
        // Clear bind group cache each frame (they're frame-specific)
        self.bind_group_cache.clear();

        loop {
            match self.surface.get_current_texture() {
                Ok(surface_texture) => {
                    let view = surface_texture
                        .texture
                        .create_view(&TextureViewDescriptor::default());
                    let encoder = self
                        .device
                        .create_command_encoder(&CommandEncoderDescriptor {
                            label: Some("frame-encoder"),
                        });

                    // Create render target textures for scene and light map
                    let (width, height) = (self.surface_config.width, self.surface_config.height);
                    let format = self.surface_config.format;
                    let scene_texture = self.device.create_texture(&TextureDescriptor {
                        label: Some("scene-texture"),
                        size: Extent3d {
                            width,
                            height,
                            depth_or_array_layers: 1,
                        },
                        mip_level_count: 1,
                        sample_count: 1,
                        dimension: TextureDimension::D2,
                        format,
                        usage: TextureUsages::RENDER_ATTACHMENT | TextureUsages::TEXTURE_BINDING,
                        view_formats: &[],
                    });
                    let scene_texture_view =
                        scene_texture.create_view(&TextureViewDescriptor::default());

                    let light_map_texture = self.device.create_texture(&TextureDescriptor {
                        label: Some("light-map-texture"),
                        size: Extent3d {
                            width,
                            height,
                            depth_or_array_layers: 1,
                        },
                        mip_level_count: 1,
                        sample_count: 1,
                        dimension: TextureDimension::D2,
                        format,
                        usage: TextureUsages::RENDER_ATTACHMENT | TextureUsages::TEXTURE_BINDING,
                        view_formats: &[],
                    });
                    let light_map_texture_view =
                        light_map_texture.create_view(&TextureViewDescriptor::default());

                    // Create occlusion texture (R8)
                    let occlusion_texture = self.device.create_texture(&TextureDescriptor {
                        label: Some("occlusion-texture"),
                        size: Extent3d {
                            width,
                            height,
                            depth_or_array_layers: 1,
                        },
                        mip_level_count: 1,
                        sample_count: 1,
                        dimension: TextureDimension::D2,
                        format: TextureFormat::R8Unorm, // Single channel for occlusion mask
                        usage: TextureUsages::RENDER_ATTACHMENT | TextureUsages::TEXTURE_BINDING,
                        view_formats: &[],
                    });
                    let occlusion_texture_view =
                        occlusion_texture.create_view(&TextureViewDescriptor::default());

                    return Ok(Frame {
                        surface_texture: Some(surface_texture),
                        view,
                        encoder: Some(encoder),
                        sprite_draws: Vec::new(),
                        light_draws: Vec::new(),
                        scene_texture: Some(scene_texture),
                        scene_texture_view: Some(scene_texture_view),
                        occlusion_texture: Some(occlusion_texture),
                        occlusion_texture_view: Some(occlusion_texture_view),
                        light_map_texture: Some(light_map_texture),
                        light_map_texture_view: Some(light_map_texture_view),
                        scene_cleared: false,
                    });
                }
                Err(e) => match e {
                        wgpu::SurfaceError::Lost | wgpu::SurfaceError::Outdated => {
                            self.surface.configure(&self.device, &self.surface_config);
                            continue;
                        }
                        wgpu::SurfaceError::Timeout => {
                            continue;
                        }
                        wgpu::SurfaceError::OutOfMemory => {
                            return Err(anyhow!("Surface ran out of memory"));
                        }
                        wgpu::SurfaceError::Other => {
                            return Err(anyhow!("Surface error: Other"));
                        }
                },
            }
        }
    }

    fn clear(&mut self, frame: &mut Frame, color: [f32; 4]) -> Result<()> {
        let encoder = frame
            .encoder
            .as_mut()
            .ok_or_else(|| anyhow!("Frame already ended"))?;

        {
            let _pass = encoder.begin_render_pass(&RenderPassDescriptor {
                label: Some("clear-pass"),
                color_attachments: &[Some(RenderPassColorAttachment {
                    view: &frame.view,
                    resolve_target: None,
                    ops: Operations {
                        load: LoadOp::Clear(wgpu::Color {
                            r: color[0] as f64,
                            g: color[1] as f64,
                            b: color[2] as f64,
                            a: color[3] as f64,
                        }),
                        store: wgpu::StoreOp::Store,
                    },
                    depth_slice: None,
                })],
                depth_stencil_attachment: None,
                multiview_mask: None,
                occlusion_query_set: None,
                timestamp_writes: None,
            });
            drop(_pass);
        }

        Ok(())
    }

    fn draw_sprite(&mut self, frame: &mut Frame, sprite: &Sprite, camera: &Camera2D) -> Result<()> {
        self.draw_texture_region(
            frame,
            sprite.texture,
            None,
            &sprite.transform,
            sprite.tint,
            sprite.is_occluder,
            camera
        )
    }

    /// Internal method to draw a texture region (or full texture)
    fn draw_texture_region(
        &mut self,
        frame: &mut Frame,
        texture_handle: TextureHandle,
        uv_rect: Option<[f32; 4]>, // x, y, w, h (normalized)
        transform: &Transform2D,
        tint: [f32; 4],
        is_occluder: bool,
        camera: &Camera2D,
    ) -> Result<()> {
        let texture = self
            .textures
            .get(&texture_handle)
            .ok_or_else(|| anyhow!("Unknown texture handle"))?;

        // Check if we've exceeded the maximum sprites per frame
        if self.uniform_write_offset >= UNIFORM_BUFFER_SIZE {
            return Err(anyhow!(
                "Too many sprites drawn in one frame (max: {})",
                MAX_SPRITES_PER_FRAME
            ));
        }

        let base_size = Vec2::new(texture.size.0 as f32, texture.size.1 as f32);
        let model = transform.to_matrix(base_size);
        let vp = camera.view_projection(self.surface_config.width, self.surface_config.height);
        let mvp = vp * model;

        let (uv_offset, uv_scale) = if let Some(rect) = uv_rect {
            ([rect[0], rect[1]], [rect[2], rect[3]])
        } else {
            ([0.0, 0.0], [1.0, 1.0])
        };

        let uniforms = SpriteUniforms {
            mvp: mvp.to_cols_array_2d(),
            color: tint,
            uv_offset,
            uv_scale,
            is_occluder: if is_occluder { 1.0 } else { 0.0 },
            _pad: [0.0; 3],
        };

        // Write uniforms at the current offset (aligned to required alignment)
        let aligned_offset = if self.uniform_write_offset == 0 {
            0
        } else {
            (self.uniform_write_offset + self.sprite_pipeline.uniform_alignment - 1)
                & !(self.sprite_pipeline.uniform_alignment - 1)
        };

        self.queue.write_buffer(
            &self.sprite_pipeline.uniform_buffer,
            aligned_offset,
            bytemuck::bytes_of(&uniforms),
        );

        // Get or create bind group for this texture (cache per texture)
        // We ensure it exists here, then look it up again when flushing
        let cache_key = (texture_handle, 0);
        let uniform_size = std::mem::size_of::<SpriteUniforms>() as u64;
        let _bind_group = self.bind_group_cache.entry(cache_key).or_insert_with(|| {
            self.device.create_bind_group(&BindGroupDescriptor {
                label: Some("sprite-bind-group"),
                layout: &self.sprite_pipeline.bind_group_layout,
                entries: &[
                    BindGroupEntry {
                        binding: 0,
                        resource: BindingResource::Buffer(wgpu::BufferBinding {
                            buffer: &self.sprite_pipeline.uniform_buffer,
                            offset: 0,
                            size: std::num::NonZeroU64::new(uniform_size),
                        }),
                    },
                    BindGroupEntry {
                        binding: 1,
                        resource: BindingResource::TextureView(&texture.view),
                    },
                    BindGroupEntry {
                        binding: 2,
                        resource: BindingResource::Sampler(&texture.sampler),
                    },
                ],
            })
        });

        // Queue the sprite draw instead of executing immediately
        frame.sprite_draws.push(SpriteDrawCommand {
            uniform_offset: aligned_offset,
            texture_handle: texture_handle,
        });

        // Advance offset for next sprite
        self.uniform_write_offset = aligned_offset + self.sprite_pipeline.uniform_alignment;

        Ok(())
    }

    /// Draw a tilemap efficiently (batched rendering with viewport culling).
    fn draw_tilemap(
        &mut self,
        frame: &mut Frame,
        tilemap: &crate::render::Tilemap,
        camera: &Camera2D,
    ) -> Result<()> {
        use crate::math::Transform2D;
        let (map_width, map_height) = tilemap.map_size;
        
        // Calculate visible tile bounds using camera viewport
        let (screen_w, screen_h) = (self.surface_config.width as f32, self.surface_config.height as f32);
        let half_screen = Vec2::new(screen_w * 0.5, screen_h * 0.5);
        let camera_scale = 1.0 / camera.zoom;
        let visible_size = Vec2::new(half_screen.x * camera_scale, half_screen.y * camera_scale);
        
        // World-space bounds of visible area
        let min_world = camera.position - visible_size;
        let max_world = camera.position + visible_size;
        
        // Convert to tile coordinates (with padding for safety)
        let (min_tile_x, min_tile_y) = tilemap.world_to_tile(min_world);
        let (max_tile_x, max_tile_y) = tilemap.world_to_tile(max_world);
        
        // Clamp to map bounds
        let start_x = (min_tile_x - 1).max(0) as u32;
        let end_x = ((max_tile_x + 1).min(map_width as i32 - 1).max(0)) as u32;
        let start_y = (min_tile_y - 1).max(0) as u32;
        let end_y = ((max_tile_y + 1).min(map_height as i32 - 1).max(0)) as u32;
        
        // Only iterate over visible tiles
        for y in start_y..=end_y.min(map_height - 1) {
            for x in start_x..=end_x.min(map_width - 1) {
                let tile = tilemap.tiles[(y * map_width + x) as usize];
                if tile.is_empty() {
                    continue;
                }

                // Get UV rect for this tile
                if let Some(uv_rect) = tilemap.tile_uv_rect(tile.id) {
                    // Calculate world position (center of tile)
                    let world_pos = tilemap.tile_to_world(x, y);
                    
                    // Create transform for this tile
                    let transform = Transform2D {
                        position: world_pos,
                        rotation: 0.0,
                        scale: tilemap.tile_size,
                    };

                    // Draw the tile using texture region
                    self.draw_texture_region(
                        frame,
                        tilemap.tileset,
                        Some(uv_rect),
                        &transform,
                        tilemap.tint,
                        true, // Tiles are occluders
                        camera,
                    )?;
                }
            }
        }

        Ok(())
    }

    /// Clear and prepare the scene texture (called at start of end_frame)
    fn clear_scene_texture(&mut self, frame: &mut Frame) -> Result<()> {
        let encoder = frame
            .encoder
            .as_mut()
            .ok_or_else(|| anyhow!("Frame already ended"))?;

        let scene_view = frame
            .scene_texture_view
            .as_ref()
            .ok_or_else(|| anyhow!("Scene texture view not available"))?;
        
        let occlusion_view = frame
            .occlusion_texture_view
            .as_ref()
            .ok_or_else(|| anyhow!("Occlusion texture view not available"))?;

        // Clear the scene texture (this happens before any drawing)
        let _pass = encoder.begin_render_pass(&RenderPassDescriptor {
            label: Some("clear-scene-pass"),
            color_attachments: &[Some(RenderPassColorAttachment {
                view: scene_view,
                resolve_target: None,
                ops: Operations {
                    // Clear to transparent so the light shader can use alpha for occlusion.
                    load: LoadOp::Clear(wgpu::Color {
                        r: 0.0,
                        g: 0.0,
                        b: 0.0,
                        a: 0.0,
                    }),
                    store: wgpu::StoreOp::Store,
                },
                depth_slice: None,
            }),
            Some(RenderPassColorAttachment {
                view: occlusion_view,
                resolve_target: None,
                ops: Operations {
                    // Clear occlusion mask (0.0 = no occlusion)
                    load: LoadOp::Clear(wgpu::Color {
                        r: 0.0,
                        g: 0.0,
                        b: 0.0,
                        a: 0.0,
                    }),
                    store: wgpu::StoreOp::Store,
                },
                depth_slice: None,
            })],
            depth_stencil_attachment: None,
            multiview_mask: None,
            occlusion_query_set: None,
            timestamp_writes: None,
        });
        // Pass is dropped here, clear is recorded

        Ok(())
    }

    /// Flush all queued sprite draws to the scene texture (called by end_frame)
    fn flush_sprites(&mut self, frame: &mut Frame) -> Result<()> {
        if frame.sprite_draws.is_empty() {
            return Ok(());
        }

        let encoder = frame
            .encoder
            .as_mut()
            .ok_or_else(|| anyhow!("Frame already ended"))?;

        // Render sprites to scene texture
        let scene_view = frame
            .scene_texture_view
            .as_ref()
            .ok_or_else(|| anyhow!("Scene texture view not available"))?;
        
        let occlusion_view = frame
            .occlusion_texture_view
            .as_ref()
            .ok_or_else(|| anyhow!("Occlusion texture view not available"))?;

        // Create render pass for sprites, rendering to scene texture
        let mut pass = encoder.begin_render_pass(&RenderPassDescriptor {
            label: Some("sprite-pass"),
            color_attachments: &[Some(RenderPassColorAttachment {
                view: scene_view,
                resolve_target: None,
                ops: Operations {
                    load: LoadOp::Load, // Load existing scene content (shapes may have been drawn)
                    store: wgpu::StoreOp::Store,
                },
                depth_slice: None,
            }),
            Some(RenderPassColorAttachment {
                view: occlusion_view,
                resolve_target: None,
                ops: Operations {
                    load: LoadOp::Load, // Load existing occlusion content
                    store: wgpu::StoreOp::Store,
                },
                depth_slice: None,
            })],
            depth_stencil_attachment: None,
            multiview_mask: None,
            occlusion_query_set: None,
            timestamp_writes: None,
        });

        pass.set_pipeline(&self.sprite_pipeline.pipeline);
        pass.set_vertex_buffer(0, self.sprite_pipeline.vertex_buffer.slice(..));

        // Draw all queued sprites
        for draw_cmd in &frame.sprite_draws {
            // Look up bind group for this texture (should be cached)
            let cache_key = (draw_cmd.texture_handle, 0);
            if let Some(bind_group) = self.bind_group_cache.get(&cache_key) {
                pass.set_bind_group(0, bind_group, &[draw_cmd.uniform_offset as u32]);
                pass.draw(0..SPRITE_VERTICES.len() as u32, 0..1);
            } else {
                return Err(anyhow!("Bind group not found for texture handle"));
            }
        }

        // Pass is dropped here, commands are recorded in encoder
        Ok(())
    }

    fn draw_point_light(
        &mut self,
        frame: &mut Frame,
        light: &PointLight,
        camera: &Camera2D,
    ) -> Result<()> {
        // Check if we've exceeded the maximum lights per frame
        const MAX_LIGHTS: usize = 256;
        if self.light_uniform_write_offset
            >= (MAX_LIGHTS as u64 * self.light_pipeline.uniform_alignment)
        {
            return Err(anyhow!(
                "Too many lights drawn in one frame (max: {})",
                MAX_LIGHTS
            ));
        }

        // Calculate MVP matrix for the light quad (scaled to light radius)
        let scale = Mat4::from_scale(Vec3::new(light.radius, light.radius, 1.0));
        let translation =
            Mat4::from_translation(Vec3::new(light.position.x, light.position.y, 0.0));
        let model = translation * scale;
        let vp = camera.view_projection(self.surface_config.width, self.surface_config.height);
        let mvp = vp * model;

        let (direction, angle) = if let Some(dir) = light.direction {
            ([dir.x, dir.y], light.angle.cos())
        } else {
            ([0.0, 0.0], 0.0) // Point light (no direction)
        };

        let uniforms = LightUniforms {
            position: [light.position.x, light.position.y],
            _pad1: [0.0, 0.0], // Padding for 16-byte alignment
            color: light.color,
            intensity: light.intensity,
            radius: light.radius,
            falloff: light.falloff,
            direction,
            angle,
            _pad2: 0.0,
            screen_size: [
                self.surface_config.width as f32,
                self.surface_config.height as f32,
            ],
            view_proj: vp.to_cols_array_2d(),
            mvp: mvp.to_cols_array_2d(),
        };

        // Write uniforms at the current offset (aligned to required alignment)
        let aligned_offset = if self.light_uniform_write_offset == 0 {
            0
        } else {
            (self.light_uniform_write_offset + self.light_pipeline.uniform_alignment - 1)
                & !(self.light_pipeline.uniform_alignment - 1)
        };

        // Manually serialize the struct (can't use Pod due to padding)
        let bytes = unsafe {
            std::slice::from_raw_parts(
                &uniforms as *const LightUniforms as *const u8,
                std::mem::size_of::<LightUniforms>(),
            )
        };
        self.queue
            .write_buffer(&self.light_pipeline.uniform_buffer, aligned_offset, bytes);

        // Queue the light draw
        frame.light_draws.push(LightDrawCommand {
            uniform_offset: aligned_offset,
        });

        // Advance offset for next light
        self.light_uniform_write_offset = aligned_offset + self.light_pipeline.uniform_alignment;

        Ok(())
    }

    fn draw_particles(
        &mut self,
        frame: &mut Frame,
        particle_system: &ParticleSystem,
        camera: &Camera2D,
        default_texture: Option<TextureHandle>,
    ) -> Result<()> {
        for emitter in particle_system.emitters() {
            let texture_handle = emitter.texture().or(default_texture);
            
            // Get texture size once per emitter
            let texture_entry = if let Some(tex) = texture_handle {
                self.textures
                    .get(&tex)
                    .ok_or_else(|| anyhow!("Unknown texture handle"))?
            } else {
                continue; // Skip if no texture
            };
            let texture_size = Vec2::new(texture_entry.size.0 as f32, texture_entry.size.1 as f32);
            
            for particle in emitter.particles() {
                if !particle.is_alive() {
                    continue;
                }

                // Particle size is in pixels, so we need to convert to scale
                // Scale = desired_size / texture_size
                let scale = Vec2::new(
                    particle.size.x / texture_size.x,
                    particle.size.y / texture_size.y,
                );

                let mut sprite = Sprite::new(texture_handle.unwrap());
                sprite.transform.position = particle.position;
                sprite.transform.scale = scale;
                sprite.transform.rotation = particle.rotation;
                sprite.tint = particle.color;

                self.draw_sprite(frame, &sprite, camera)?;
            }
        }
        Ok(())
    }

    fn clear_light_map_to_white(&mut self, frame: &mut Frame) -> Result<()> {
        let encoder = frame
            .encoder
            .as_mut()
            .ok_or_else(|| anyhow!("Frame already ended"))?;

        let light_map_view = frame
            .light_map_texture_view
            .as_ref()
            .ok_or_else(|| anyhow!("Light map texture view not available"))?;

        // Clear light map to white (0.75, 0.75, 0.75) so that when composite adds ambient (0.25),
        // we get 0.25 + 0.75 = 1.0, which means no darkening of the scene
        let pass = encoder.begin_render_pass(&RenderPassDescriptor {
            label: Some("clear-light-map"),
            color_attachments: &[Some(RenderPassColorAttachment {
                view: light_map_view,
                resolve_target: None,
                ops: Operations {
                    load: LoadOp::Clear(wgpu::Color {
                        r: 0.75,
                        g: 0.75,
                        b: 0.75,
                        a: 1.0,
                    }),
                    store: wgpu::StoreOp::Store,
                },
                depth_slice: None,
            })],
            depth_stencil_attachment: None,
            multiview_mask: None,
            occlusion_query_set: None,
            timestamp_writes: None,
        });
        drop(pass);
        Ok(())
    }

    fn flush_lights(&mut self, frame: &mut Frame) -> Result<()> {
        if frame.light_draws.is_empty() {
            return Ok(());
        }

        let encoder = frame
            .encoder
            .as_mut()
            .ok_or_else(|| anyhow!("Frame already ended"))?;

        // Render lights to light map texture (additive blending)
        let light_map_view = frame
            .light_map_texture_view
            .as_ref()
            .ok_or_else(|| anyhow!("Light map texture view not available"))?;

        // Create render pass for lights, rendering to light map texture
        let mut pass = encoder.begin_render_pass(&RenderPassDescriptor {
            label: Some("light-batch-pass"),
            color_attachments: &[Some(RenderPassColorAttachment {
                view: light_map_view,
                resolve_target: None,
                ops: Operations {
                    load: LoadOp::Clear(wgpu::Color {
                        r: 0.0,
                        g: 0.0,
                        b: 0.0,
                        a: 1.0,
                    }), // Clear light map (black = no light)
                    store: wgpu::StoreOp::Store,
                },
                depth_slice: None,
            })],
            depth_stencil_attachment: None,
            multiview_mask: None,
            occlusion_query_set: None,
            timestamp_writes: None,
        });

        pass.set_pipeline(&self.light_pipeline.pipeline);
        pass.set_vertex_buffer(0, self.light_pipeline.vertex_buffer.slice(..));

        // Create bind group for lights (shared for all lights, using dynamic offset)
        let uniform_size = std::mem::size_of::<LightUniforms>() as u64;
        let occlusion_view = frame
            .occlusion_texture_view
            .as_ref()
            .ok_or_else(|| anyhow!("Occlusion texture view not available"))?;

        // Create sampler for occlusion texture
        let sampler = self.device.create_sampler(&SamplerDescriptor {
            label: Some("light-occlusion-sampler"),
            address_mode_u: AddressMode::ClampToEdge,
            address_mode_v: AddressMode::ClampToEdge,
            address_mode_w: AddressMode::ClampToEdge,
            mag_filter: FilterMode::Linear,
            min_filter: FilterMode::Linear,
            mipmap_filter: wgpu::MipmapFilterMode::Nearest,
            ..Default::default()
        });

        let bind_group = self.device.create_bind_group(&BindGroupDescriptor {
            label: Some("light-bind-group"),
            layout: &self.light_pipeline.bind_group_layout,
            entries: &[
                BindGroupEntry {
                    binding: 0,
                    resource: BindingResource::Buffer(wgpu::BufferBinding {
                        buffer: &self.light_pipeline.uniform_buffer,
                        offset: 0,
                        size: std::num::NonZeroU64::new(uniform_size),
                    }),
                },
                BindGroupEntry {
                    binding: 1,
                    resource: BindingResource::TextureView(occlusion_view),
                },
                BindGroupEntry {
                    binding: 2,
                    resource: BindingResource::Sampler(&sampler),
                },
            ],
        });

        // Draw all queued lights
        for draw_cmd in &frame.light_draws {
            pass.set_bind_group(0, &bind_group, &[draw_cmd.uniform_offset as u32]);
            pass.draw(0..6, 0..1); // 6 vertices for quad
        }

        drop(pass);
        Ok(())
    }

    fn end_frame(&mut self, mut frame: Frame) -> Result<()> {
        // Step 0: Clear scene texture if not already cleared (shapes may have cleared it)
        if !frame.scene_cleared {
            self.clear_scene_texture(&mut frame)?;
            frame.scene_cleared = true;
        }

        // Step 1: Render sprites to scene texture (shapes were already drawn during draw() phase)
        self.flush_sprites(&mut frame)?;

        // Step 2: Render lights to light map texture (additive)
        // If there are no lights, clear light map to white so composite doesn't darken the scene
        if frame.light_draws.is_empty() {
            self.clear_light_map_to_white(&mut frame)?;
        } else {
            self.flush_lights(&mut frame)?;
        }

        // Step 3: Composite scene and light map to final surface
        self.composite_scene_and_lights(&mut frame)?;

        let encoder = frame
            .encoder
            .take()
            .ok_or_else(|| anyhow!("Frame already ended"))?;
        self.queue.submit(Some(encoder.finish()));

        // Clean up render target textures (they'll be recreated next frame)
        drop(frame.scene_texture.take());
        drop(frame.scene_texture.take());
        drop(frame.scene_texture_view.take());
        drop(frame.occlusion_texture.take());
        drop(frame.occlusion_texture_view.take());
        drop(frame.light_map_texture.take());
        drop(frame.light_map_texture_view.take());

        let surface_texture = frame
            .surface_texture
            .take()
            .ok_or_else(|| anyhow!("Frame already ended"))?;
        surface_texture.present();
        Ok(())
    }

    fn composite_scene_and_lights(&mut self, frame: &mut Frame) -> Result<()> {
        let encoder = frame
            .encoder
            .as_mut()
            .ok_or_else(|| anyhow!("Frame already ended"))?;

        let scene_view = frame
            .scene_texture_view
            .as_ref()
            .ok_or_else(|| anyhow!("Scene texture view not available"))?;
        let light_map_view = frame
            .light_map_texture_view
            .as_ref()
            .ok_or_else(|| anyhow!("Light map texture view not available"))?;

        // Create sampler for textures
        let sampler = self.device.create_sampler(&SamplerDescriptor {
            label: Some("composite-sampler"),
            address_mode_u: AddressMode::ClampToEdge,
            address_mode_v: AddressMode::ClampToEdge,
            address_mode_w: AddressMode::ClampToEdge,
            mag_filter: FilterMode::Linear,
            min_filter: FilterMode::Linear,
            mipmap_filter: wgpu::MipmapFilterMode::Nearest,
            ..Default::default()
        });

        // Create bind group for composite shader
        let bind_group = self.device.create_bind_group(&BindGroupDescriptor {
            label: Some("composite-bind-group"),
            layout: &self.composite_pipeline.bind_group_layout,
            entries: &[
                BindGroupEntry {
                    binding: 0,
                    resource: BindingResource::TextureView(scene_view),
                },
                BindGroupEntry {
                    binding: 1,
                    resource: BindingResource::Sampler(&sampler),
                },
                BindGroupEntry {
                    binding: 2,
                    resource: BindingResource::TextureView(light_map_view),
                },
                BindGroupEntry {
                    binding: 3,
                    resource: BindingResource::Sampler(&sampler),
                },
            ],
        });

        // Render composite to final surface
        let mut pass = encoder.begin_render_pass(&RenderPassDescriptor {
            label: Some("composite-pass"),
            color_attachments: &[Some(RenderPassColorAttachment {
                view: &frame.view,
                resolve_target: None,
                ops: Operations {
                    load: LoadOp::Clear(wgpu::Color {
                        r: 0.0,
                        g: 0.0,
                        b: 0.0,
                        a: 1.0,
                    }),
                    store: wgpu::StoreOp::Store,
                },
                depth_slice: None,
            })],
            depth_stencil_attachment: None,
            multiview_mask: None,
            occlusion_query_set: None,
            timestamp_writes: None,
        });

        pass.set_pipeline(&self.composite_pipeline.pipeline);
        pass.set_bind_group(0, &bind_group, &[]);
        pass.set_vertex_buffer(0, self.composite_pipeline.vertex_buffer.slice(..));
        pass.draw(0..6, 0..1); // Fullscreen quad

        drop(pass);
        Ok(())
    }

    fn load_texture_from_file(&mut self, path: &str) -> Result<TextureHandle> {
        let data = fs::read(path)?;
        self.load_texture_from_bytes(&data)
    }

    fn load_texture_from_bytes(&mut self, bytes: &[u8]) -> Result<TextureHandle> {
        let image = image::load_from_memory(bytes)?.to_rgba8();
        let dimensions = image.dimensions();
        // Regular image textures use linear filtering
        self.load_texture_from_rgba(&image, dimensions.0, dimensions.1, false)
    }

    /// Load a texture from raw RGBA8 data (for glyphs, etc.)
    /// `is_font_texture`: if true, uses Nearest filtering for crisp text rendering
    pub(crate) fn load_texture_from_rgba(
        &mut self,
        data: &[u8],
        width: u32,
        height: u32,
        is_font_texture: bool,
    ) -> Result<TextureHandle> {
        let size = Extent3d {
            width,
            height,
            depth_or_array_layers: 1,
        };

        let texture = self.device.create_texture(&TextureDescriptor {
            label: Some("texture"),
            size,
            mip_level_count: 1,
            sample_count: 1,
            dimension: TextureDimension::D2,
            format: TextureFormat::Rgba8UnormSrgb,
            usage: TextureUsages::TEXTURE_BINDING | TextureUsages::COPY_DST,
            view_formats: &[],
        });

        self.queue.write_texture(
            TexelCopyTextureInfo {
                texture: &texture,
                mip_level: 0,
                origin: Origin3d::ZERO,
                aspect: TextureAspect::All,
            },
            data,
            TexelCopyBufferLayout {
                offset: 0,
                bytes_per_row: Some(4 * width),
                rows_per_image: Some(height),
            },
            size,
        );

        let view = texture.create_view(&TextureViewDescriptor::default());

        // Filtering mode selection:
        // - Font textures: Nearest for crisp, pixel-perfect rendering
        // - Regular sprites: Linear for smooth scaling
        let (mag_filter, min_filter) = if is_font_texture {
            (FilterMode::Nearest, FilterMode::Nearest)
        } else {
            (FilterMode::Linear, FilterMode::Linear)
        };

        let sampler = self.device.create_sampler(&SamplerDescriptor {
            label: Some(if is_font_texture {
                "font-sampler"
            } else {
                "sprite-sampler"
            }),
            address_mode_u: AddressMode::ClampToEdge,
            address_mode_v: AddressMode::ClampToEdge,
            address_mode_w: AddressMode::ClampToEdge,
            mag_filter,
            min_filter,
            mipmap_filter: wgpu::MipmapFilterMode::Nearest, // No mipmaps for fonts
            ..Default::default()
        });

        let handle = TextureHandle(self.next_texture_id);
        self.next_texture_id += 1;
        self.textures.insert(
            handle,
            TextureEntry {
                texture,
                view,
                sampler,
                size: (width, height),
            },
        );

        Ok(handle)
    }

    fn texture_size(&self, handle: TextureHandle) -> Option<(u32, u32)> {
        self.textures.get(&handle).map(|t| t.size)
    }

    fn surface_size(&self) -> (u32, u32) {
        (self.surface_config.width, self.surface_config.height)
    }

    fn load_font_from_bytes(&mut self, bytes: &[u8]) -> Result<FontHandle> {
        self.text_renderer.load_font_from_bytes(bytes)
    }

    /// Ensure all characters in the text are rasterized and cached.
    /// Glyphon handles glyph caching internally, so this is a no-op.
    fn ensure_glyphs_rasterized(
        &mut self,
        _text: &str,
        _font: FontHandle,
        _size: f32,
    ) -> Result<()> {
        // Glyphon handles glyph caching internally, no pre-rasterization needed
        Ok(())
    }

    fn draw_text(
        &mut self,
        frame: &mut Frame,
        text: &str,
        _font: FontHandle,
        size: f32,
        position: Vec2,
        color: [f32; 4],
        camera: &Camera2D,
    ) -> Result<()> {
        // Ensure text components are initialized
        self.ensure_text_components_initialized()?;
        
        // Get mutable references to text rendering components
        let (text_atlas, text_renderer, viewport, font_system, cache) = self.text_renderer
            .get_rendering_refs()
            .ok_or_else(|| anyhow!("Text components not initialized"))?;
        
        // Shape the text - API: set_text(font_system, text, attrs, shaping, align)
        let mut buffer = GlyphonBuffer::new(font_system, Metrics::new(size, size * 1.2));
        let attrs = Attrs::new().family(Family::Name("sans-serif"));
        buffer.set_text(font_system, text, &attrs, Shaping::Advanced, None);
        buffer.shape_until_scroll(font_system, false);
        
        // Convert world position to screen coordinates using camera
        let (screen_w, screen_h) = (self.surface_config.width, self.surface_config.height);
        let screen_pos = camera.world_to_screen(position, screen_w, screen_h);
        
        // Create text area - add custom_glyphs field
        let text_area = TextArea {
            buffer: &buffer,
            left: screen_pos.x,
            top: screen_pos.y,
            scale: 1.0,
            bounds: glyphon::TextBounds {
                left: 0,
                top: 0,
                right: screen_w as i32,
                bottom: screen_h as i32,
            },
            default_color: Color::rgba(
                (color[0] * 255.0) as u8,
                (color[1] * 255.0) as u8,
                (color[2] * 255.0) as u8,
                (color[3] * 255.0) as u8,
            ),
            custom_glyphs: &[],
        };
        
        // Prepare text for rendering - prepare is on TextRenderer, not TextAtlas
        // API: text_renderer.prepare(device, queue, font_system, atlas, viewport, text_areas, cache)
        text_renderer.prepare(
            &self.device,
            &self.queue,
            font_system,
            text_atlas,
            viewport,
            [text_area],
            cache,
        )?;
        
        // Get encoder and scene texture view for rendering
        let encoder = frame
            .encoder
            .as_mut()
            .ok_or_else(|| anyhow!("Frame already ended"))?;
        
        let scene_view = frame
            .scene_texture_view
            .as_ref()
            .ok_or_else(|| anyhow!("Scene texture view not available"))?;
        
        // Render text to scene texture
        let mut pass = encoder.begin_render_pass(&RenderPassDescriptor {
            label: Some("text-pass"),
            color_attachments: &[Some(RenderPassColorAttachment {
                view: scene_view,
                resolve_target: None,
                ops: Operations {
                    load: LoadOp::Load, // Load existing scene content
                    store: wgpu::StoreOp::Store,
                },
                depth_slice: None,
            })],
            depth_stencil_attachment: None,
            multiview_mask: None,
            occlusion_query_set: None,
            timestamp_writes: None,
        });
        
        // Render - API: render(atlas, viewport, pass) - renders whatever was prepared
        text_renderer.render(&text_atlas, viewport, &mut pass)?;
        
        drop(pass);

        Ok(())
    }

    /// Measure the width of text without drawing it.
    /// This is useful for accurate text alignment in HUD elements.
    fn measure_text_width(&mut self, _text: &str, _font: FontHandle, _size: f32) -> Result<f32> {
        // TODO: Implement glyphon-based text measurement
        // For now, return 0.0
        Ok(0.0)
    }

    fn draw_polygon(
        &mut self,
        frame: &mut Frame,
        points: &[Vec2],
        color: [f32; 4],
        camera: &Camera2D,
        is_occluder: bool,
    ) -> Result<()> {
        if points.len() < 3 {
            return Ok(()); // Need at least 3 points for a triangle
        }

        // Triangulate polygon using ear clipping
        let triangles = self.triangulate_polygon(points);
        if triangles.is_empty() {
            return Ok(());
        }

        // Create vertex buffer for this polygon
        let vertices: Vec<ShapeVertex> = triangles
            .iter()
            .flat_map(|&(i0, i1, i2)| {
                vec![
                    ShapeVertex {
                        position: [points[i0].x, points[i0].y],
                    },
                    ShapeVertex {
                        position: [points[i1].x, points[i1].y],
                    },
                    ShapeVertex {
                        position: [points[i2].x, points[i2].y],
                    },
                ]
            })
            .collect();

        let vertex_buffer = self
            .device
            .create_buffer_init(&wgpu::util::BufferInitDescriptor {
            label: Some("shape-vertices"),
            contents: bytemuck::cast_slice(&vertices),
            usage: BufferUsages::VERTEX,
        });

        // Create MVP matrix
        let vp = camera.view_projection(self.surface_config.width, self.surface_config.height);
        let mvp = vp.to_cols_array_2d();

        let uniforms = ShapeUniforms {
             mvp,
             color,
             is_occluder: if is_occluder { 1.0 } else { 0.0 },
             _pad: [0.0; 3],
        };

        // Write uniforms
        self.queue.write_buffer(
            &self.shape_pipeline.uniform_buffer,
            0,
            bytemuck::bytes_of(&uniforms),
        );

        // Create bind group
        let bind_group = self.device.create_bind_group(&BindGroupDescriptor {
            label: Some("shape-bind-group"),
            layout: &self.shape_pipeline.bind_group_layout,
            entries: &[BindGroupEntry {
                binding: 0,
                resource: BindingResource::Buffer(wgpu::BufferBinding {
                    buffer: &self.shape_pipeline.uniform_buffer,
                    offset: 0,
                    size: std::num::NonZeroU64::new(std::mem::size_of::<ShapeUniforms>() as u64),
                }),
            }],
        });

        // Draw in a render pass to scene texture
        // Clear scene texture on first shape draw if not already cleared
        let encoder = frame
            .encoder
            .as_mut()
            .ok_or_else(|| anyhow!("Frame already ended"))?;

        let scene_view = frame
            .scene_texture_view
            .as_ref()
            .ok_or_else(|| anyhow!("Scene texture view not available"))?;
        
        // Fix: Use correct occlusion view binding
        let occlusion_view = frame
            .occlusion_texture_view
            .as_ref()
            .ok_or_else(|| anyhow!("Occlusion texture view not available"))?;

        // Clear scene texture on first draw if not already cleared
        if !frame.scene_cleared {
            let _clear_pass = encoder.begin_render_pass(&RenderPassDescriptor {
                label: Some("clear-scene-first"),
                color_attachments: &[Some(RenderPassColorAttachment {
                    view: scene_view,
                    resolve_target: None,
                    ops: Operations {
                        // Keep background transparent so only geometry occludes light rays.
                        load: LoadOp::Clear(wgpu::Color {
                            r: 0.0,
                            g: 0.0,
                            b: 0.0,
                            a: 0.0,
                        }),
                        store: wgpu::StoreOp::Store,
                    },
                    depth_slice: None,
                }),
                Some(RenderPassColorAttachment {
                    view: occlusion_view,
                    resolve_target: None,
                    ops: Operations {
                        load: LoadOp::Clear(wgpu::Color {
                            r: 0.0,
                            g: 0.0,
                            b: 0.0,
                            a: 0.0,
                        }),
                        store: wgpu::StoreOp::Store,
                    },
                    depth_slice: None,
                })],
                depth_stencil_attachment: None,
                multiview_mask: None,
                occlusion_query_set: None,
                timestamp_writes: None,
            });
            frame.scene_cleared = true;
        }

        let mut pass = encoder.begin_render_pass(&RenderPassDescriptor {
            label: Some("shape-pass"),
            color_attachments: &[Some(RenderPassColorAttachment {
                view: scene_view,
                resolve_target: None,
                ops: Operations {
                    load: LoadOp::Load, // Load existing scene content
                    store: wgpu::StoreOp::Store,
                },
                depth_slice: None,
            }),
            Some(RenderPassColorAttachment {
                view: occlusion_view,
                resolve_target: None,
                ops: Operations {
                    load: LoadOp::Load, // Load existing occlusion content
                    store: wgpu::StoreOp::Store,
                },
                depth_slice: None,
            })],
            depth_stencil_attachment: None,
            multiview_mask: None,
            occlusion_query_set: None,
            timestamp_writes: None,
        });

        pass.set_pipeline(&self.shape_pipeline.pipeline);
        pass.set_bind_group(0, &bind_group, &[]);
        pass.set_vertex_buffer(0, vertex_buffer.slice(..));
        pass.draw(0..vertices.len() as u32, 0..1);

        drop(pass);

        Ok(())
    }

    fn draw_circle(
        &mut self,
        frame: &mut Frame,
        center: Vec2,
        radius: f32,
        color: [f32; 4],
        camera: &Camera2D,
    ) -> Result<()> {
        if radius <= 0.0 {
            return Ok(());
        }

        // Generate circle vertices using triangle fan
        const SEGMENTS: usize = 32;
        let mut vertices = Vec::with_capacity((SEGMENTS + 2) * 3);
        
        // Center vertex
        vertices.push(ShapeVertex {
            position: [center.x, center.y],
        });

        // Generate circle points
        for i in 0..=SEGMENTS {
            let angle = (i as f32 / SEGMENTS as f32) * std::f32::consts::TAU;
            vertices.push(ShapeVertex {
                position: [
                    center.x + radius * angle.cos(),
                    center.y + radius * angle.sin(),
                ],
            });
        }

        // Create triangles (fan from center)
        let mut triangles = Vec::with_capacity(SEGMENTS * 3);
        for i in 0..SEGMENTS {
            triangles.push(ShapeVertex {
                position: vertices[0].position,
            });
            triangles.push(vertices[i + 1]);
            triangles.push(vertices[i + 2]);
        }

        let vertex_buffer = self
            .device
            .create_buffer_init(&wgpu::util::BufferInitDescriptor {
            label: Some("circle-vertices"),
            contents: bytemuck::cast_slice(&triangles),
            usage: BufferUsages::VERTEX,
        });

        // Create MVP matrix
        let vp = camera.view_projection(self.surface_config.width, self.surface_config.height);
        let mvp = vp.to_cols_array_2d();

        let uniforms = ShapeUniforms {
             mvp,
             color,
             is_occluder: 1.0, // Default to occluder
             _pad: [0.0; 3],
        };

        // Write uniforms
        self.queue.write_buffer(
            &self.shape_pipeline.uniform_buffer,
            0,
            bytemuck::bytes_of(&uniforms),
        );

        // Create bind group
        let bind_group = self.device.create_bind_group(&BindGroupDescriptor {
            label: Some("shape-bind-group"),
            layout: &self.shape_pipeline.bind_group_layout,
            entries: &[BindGroupEntry {
                binding: 0,
                resource: BindingResource::Buffer(wgpu::BufferBinding {
                    buffer: &self.shape_pipeline.uniform_buffer,
                    offset: 0,
                    size: std::num::NonZeroU64::new(std::mem::size_of::<ShapeUniforms>() as u64),
                }),
            }],
        });

        // Draw in a render pass to scene texture
        let encoder = frame
            .encoder
            .as_mut()
            .ok_or_else(|| anyhow!("Frame already ended"))?;

        let scene_view = frame
            .scene_texture_view
            .as_ref()
            .ok_or_else(|| anyhow!("Scene texture view not available"))?;
        
        let occlusion_view = frame
            .occlusion_texture_view
            .as_ref()
            .ok_or_else(|| anyhow!("Occlusion texture view not available"))?;

        let mut pass = encoder.begin_render_pass(&RenderPassDescriptor {
            label: Some("shape-pass"),
            color_attachments: &[Some(RenderPassColorAttachment {
                view: scene_view,
                resolve_target: None,
                ops: Operations {
                    load: LoadOp::Load, // Load existing scene content
                    store: wgpu::StoreOp::Store,
                },
                depth_slice: None,
            }),
            Some(RenderPassColorAttachment {
                view: occlusion_view,
                resolve_target: None,
                ops: Operations {
                    load: LoadOp::Load, // Load existing occlusion content
                    store: wgpu::StoreOp::Store,
                },
                depth_slice: None,
            })],
            depth_stencil_attachment: None,
            multiview_mask: None,
            occlusion_query_set: None,
            timestamp_writes: None,
        });

        pass.set_pipeline(&self.shape_pipeline.pipeline);
        pass.set_bind_group(0, &bind_group, &[]);
        pass.set_vertex_buffer(0, vertex_buffer.slice(..));
        pass.draw(0..triangles.len() as u32, 0..1);

        drop(pass);

        Ok(())
    }

    /// Triangulate a polygon using ear clipping algorithm
    fn triangulate_polygon(&self, points: &[Vec2]) -> Vec<(usize, usize, usize)> {
        if points.len() < 3 {
            return Vec::new();
        }

        // For simple convex polygons, use fan triangulation
        // For more complex cases, we'd use ear clipping, but fan works for most game cases
        let mut triangles = Vec::new();
        for i in 1..(points.len() - 1) {
            triangles.push((0, i, i + 1));
        }
        triangles
    }
}

fn create_sprite_pipeline(device: &wgpu::Device, surface_format: TextureFormat) -> SpritePipeline {
    let shader = device.create_shader_module(ShaderModuleDescriptor {
        label: Some("sprite-shader"),
        source: ShaderSource::Wgsl(include_str!("sprite.wgsl").into()),
    });

    let bind_group_layout = device.create_bind_group_layout(&BindGroupLayoutDescriptor {
        label: Some("sprite-bind-group-layout"),
        entries: &[
            BindGroupLayoutEntry {
                binding: 0,
                visibility: wgpu::ShaderStages::VERTEX_FRAGMENT,
                ty: BindingType::Buffer {
                    ty: BufferBindingType::Uniform,
                    has_dynamic_offset: true, // Enable dynamic offsets
                    min_binding_size: std::num::NonZeroU64::new(
                        std::mem::size_of::<SpriteUniforms>() as u64,
                    ),
                },
                count: None,
            },
            BindGroupLayoutEntry {
                binding: 1,
                visibility: wgpu::ShaderStages::FRAGMENT,
                ty: BindingType::Texture {
                    sample_type: TextureSampleType::Float { filterable: true },
                    view_dimension: TextureViewDimension::D2,
                    multisampled: false,
                },
                count: None,
            },
            BindGroupLayoutEntry {
                binding: 2,
                visibility: wgpu::ShaderStages::FRAGMENT,
                ty: BindingType::Sampler(SamplerBindingType::Filtering),
                count: None,
            },
        ],
    });

    let pipeline_layout = device.create_pipeline_layout(&PipelineLayoutDescriptor {
        label: Some("sprite-pipeline-layout"),
        bind_group_layouts: &[&bind_group_layout],
        immediate_size: 0,
    });

    let vertex_buffer = device.create_buffer_init(&wgpu::util::BufferInitDescriptor {
        label: Some("sprite-vertices"),
        contents: bytemuck::cast_slice(&SPRITE_VERTICES),
        usage: BufferUsages::VERTEX,
    });

    // Get the required uniform buffer alignment (usually 256 bytes)
    let uniform_alignment = device.limits().min_uniform_buffer_offset_alignment as u64;
    let uniform_size = std::mem::size_of::<SpriteUniforms>() as u64;
    // Round up to alignment (not used directly, but kept for reference)
    let _aligned_uniform_size = (uniform_size + uniform_alignment - 1) & !(uniform_alignment - 1);

    let uniform_buffer = device.create_buffer(&wgpu::BufferDescriptor {
        label: Some("sprite-uniform-buffer"),
        size: UNIFORM_BUFFER_SIZE,
        usage: BufferUsages::UNIFORM | BufferUsages::COPY_DST,
        mapped_at_creation: false,
    });

    let pipeline = device.create_render_pipeline(&RenderPipelineDescriptor {
        label: Some("sprite-pipeline"),
        layout: Some(&pipeline_layout),
        vertex: VertexState {
            module: &shader,
            entry_point: Some("vs_main"),
            buffers: &[wgpu::VertexBufferLayout {
                array_stride: std::mem::size_of::<SpriteVertex>() as wgpu::BufferAddress,
                step_mode: wgpu::VertexStepMode::Vertex,
                attributes: &vertex_attr_array![0 => Float32x2, 1 => Float32x2],
            }],
            compilation_options: wgpu::PipelineCompilationOptions::default(),
        },
        fragment: Some(FragmentState {
            module: &shader,
            entry_point: Some("fs_main"),
            targets: &[Some(ColorTargetState {
                format: surface_format,
                blend: Some(wgpu::BlendState::ALPHA_BLENDING),
                write_mask: ColorWrites::ALL,
            }),
            // Occlusion target (R8)
            Some(ColorTargetState {
                format: TextureFormat::R8Unorm,
                blend: Some(wgpu::BlendState::REPLACE),
                write_mask: ColorWrites::ALL,
            })],
            compilation_options: wgpu::PipelineCompilationOptions::default(),
        }),
        primitive: PrimitiveState::default(),
        depth_stencil: None,
        multisample: MultisampleState::default(),
        multiview_mask: None,
        cache: None,
    });

    SpritePipeline {
        pipeline,
        vertex_buffer,
        uniform_buffer,
        bind_group_layout,
        uniform_buffer_size: UNIFORM_BUFFER_SIZE,
        uniform_alignment,
    }
}

fn create_light_pipeline(device: &wgpu::Device, surface_format: TextureFormat) -> LightPipeline {
    let shader = device.create_shader_module(ShaderModuleDescriptor {
        label: Some("light-shader"),
        source: ShaderSource::Wgsl(include_str!("light.wgsl").into()),
    });

    let bind_group_layout = device.create_bind_group_layout(&BindGroupLayoutDescriptor {
        label: Some("light-bind-group-layout"),
        entries: &[
            BindGroupLayoutEntry {
                binding: 0,
                visibility: wgpu::ShaderStages::VERTEX_FRAGMENT,
                ty: BindingType::Buffer {
                    ty: BufferBindingType::Uniform,
                    has_dynamic_offset: true,
                    min_binding_size: std::num::NonZeroU64::new(
                        std::mem::size_of::<LightUniforms>() as u64,
                    ),
                },
                count: None,
            },
            BindGroupLayoutEntry {
                binding: 1,
                visibility: wgpu::ShaderStages::FRAGMENT,
                ty: BindingType::Texture {
                    sample_type: TextureSampleType::Float { filterable: true },
                    view_dimension: TextureViewDimension::D2,
                    multisampled: false,
                },
                count: None,
            },
            BindGroupLayoutEntry {
                binding: 2,
                visibility: wgpu::ShaderStages::FRAGMENT,
                ty: BindingType::Sampler(SamplerBindingType::Filtering),
                count: None,
            },
        ],
    });

    let pipeline_layout = device.create_pipeline_layout(&PipelineLayoutDescriptor {
        label: Some("light-pipeline-layout"),
        bind_group_layouts: &[&bind_group_layout],
        immediate_size: 0,
    });

    let uniform_alignment = device.limits().min_uniform_buffer_offset_alignment as u64;
    let uniform_size = std::mem::size_of::<LightUniforms>() as u64;
    let aligned_uniform_size = (uniform_size + uniform_alignment - 1) & !(uniform_alignment - 1);

    // Create uniform buffer (large enough for many lights)
    const MAX_LIGHTS: usize = 256;
    let uniform_buffer = device.create_buffer(&wgpu::BufferDescriptor {
        label: Some("light-uniform-buffer"),
        size: aligned_uniform_size * MAX_LIGHTS as u64,
        usage: BufferUsages::UNIFORM | BufferUsages::COPY_DST,
        mapped_at_creation: false,
    });

    // Create vertex buffer for light quad
    let light_vertices: [ShapeVertex; 6] = [
        ShapeVertex {
            position: [-1.0, -1.0],
        }, // Bottom-left
        ShapeVertex {
            position: [1.0, -1.0],
        }, // Bottom-right
        ShapeVertex {
            position: [-1.0, 1.0],
        }, // Top-left
        ShapeVertex {
            position: [1.0, -1.0],
        }, // Bottom-right
        ShapeVertex {
            position: [1.0, 1.0],
        }, // Top-right
        ShapeVertex {
            position: [-1.0, 1.0],
        }, // Top-left
    ];

    let vertex_buffer = device.create_buffer_init(&wgpu::util::BufferInitDescriptor {
        label: Some("light-vertex-buffer"),
        contents: bytemuck::cast_slice(&light_vertices),
        usage: BufferUsages::VERTEX,
    });

    // Additive blending for light map accumulation
    // Lights accumulate additively in the light map texture
    let blend = wgpu::BlendState {
        color: wgpu::BlendComponent {
            src_factor: wgpu::BlendFactor::One,
            dst_factor: wgpu::BlendFactor::One,
            operation: wgpu::BlendOperation::Add,
        },
        alpha: wgpu::BlendComponent {
            src_factor: wgpu::BlendFactor::One,
            dst_factor: wgpu::BlendFactor::One,
            operation: wgpu::BlendOperation::Add,
        },
    };

    let pipeline = device.create_render_pipeline(&RenderPipelineDescriptor {
        label: Some("light-pipeline"),
        layout: Some(&pipeline_layout),
        vertex: VertexState {
            module: &shader,
            entry_point: Some("vs_main"),
            buffers: &[wgpu::VertexBufferLayout {
                array_stride: std::mem::size_of::<ShapeVertex>() as wgpu::BufferAddress,
                step_mode: wgpu::VertexStepMode::Vertex,
                attributes: &vertex_attr_array![0 => Float32x2],
            }],
            compilation_options: wgpu::PipelineCompilationOptions::default(),
        },
        fragment: Some(FragmentState {
            module: &shader,
            entry_point: Some("fs_main"),
            targets: &[Some(ColorTargetState {
                format: surface_format,
                blend: Some(blend),
                write_mask: ColorWrites::ALL,
            })],
            compilation_options: wgpu::PipelineCompilationOptions::default(),
        }),
        primitive: PrimitiveState {
            topology: wgpu::PrimitiveTopology::TriangleList,
            strip_index_format: None,
            front_face: wgpu::FrontFace::Ccw,
            cull_mode: None,
            unclipped_depth: false,
            polygon_mode: wgpu::PolygonMode::Fill,
            conservative: false,
        },
        depth_stencil: None,
        multisample: MultisampleState::default(),
        multiview_mask: None,
        cache: None,
    });

    LightPipeline {
        pipeline,
        bind_group_layout,
        uniform_buffer,
        uniform_alignment,
        vertex_buffer,
    }
}

fn create_composite_pipeline(
    device: &wgpu::Device,
    surface_format: TextureFormat,
) -> CompositePipeline {
    let shader = device.create_shader_module(ShaderModuleDescriptor {
        label: Some("composite-shader"),
        source: ShaderSource::Wgsl(include_str!("composite.wgsl").into()),
    });

    let bind_group_layout = device.create_bind_group_layout(&BindGroupLayoutDescriptor {
        label: Some("composite-bind-group-layout"),
        entries: &[
            BindGroupLayoutEntry {
                binding: 0,
                visibility: wgpu::ShaderStages::FRAGMENT,
                ty: BindingType::Texture {
                    sample_type: TextureSampleType::Float { filterable: true },
                    view_dimension: TextureViewDimension::D2,
                    multisampled: false,
                },
                count: None,
            },
            BindGroupLayoutEntry {
                binding: 1,
                visibility: wgpu::ShaderStages::FRAGMENT,
                ty: BindingType::Sampler(SamplerBindingType::Filtering),
                count: None,
            },
            BindGroupLayoutEntry {
                binding: 2,
                visibility: wgpu::ShaderStages::FRAGMENT,
                ty: BindingType::Texture {
                    sample_type: TextureSampleType::Float { filterable: true },
                    view_dimension: TextureViewDimension::D2,
                    multisampled: false,
                },
                count: None,
            },
            BindGroupLayoutEntry {
                binding: 3,
                visibility: wgpu::ShaderStages::FRAGMENT,
                ty: BindingType::Sampler(SamplerBindingType::Filtering),
                count: None,
            },
        ],
    });

    let pipeline_layout = device.create_pipeline_layout(&PipelineLayoutDescriptor {
        label: Some("composite-pipeline-layout"),
        bind_group_layouts: &[&bind_group_layout],
        immediate_size: 0,
    });

    // Fullscreen quad vertices (NDC coordinates: -1 to 1)
    let quad_vertices: [SpriteVertex; 6] = [
        SpriteVertex {
            position: [-1.0, -1.0],
            uv: [0.0, 1.0],
        }, // Bottom-left
        SpriteVertex {
            position: [1.0, -1.0],
            uv: [1.0, 1.0],
        }, // Bottom-right
        SpriteVertex {
            position: [-1.0, 1.0],
            uv: [0.0, 0.0],
        }, // Top-left
        SpriteVertex {
            position: [1.0, -1.0],
            uv: [1.0, 1.0],
        }, // Bottom-right
        SpriteVertex {
            position: [1.0, 1.0],
            uv: [1.0, 0.0],
        }, // Top-right
        SpriteVertex {
            position: [-1.0, 1.0],
            uv: [0.0, 0.0],
        }, // Top-left
    ];

    let vertex_buffer = device.create_buffer_init(&wgpu::util::BufferInitDescriptor {
        label: Some("composite-vertex-buffer"),
        contents: bytemuck::cast_slice(&quad_vertices),
        usage: BufferUsages::VERTEX,
    });

    let pipeline = device.create_render_pipeline(&RenderPipelineDescriptor {
        label: Some("composite-pipeline"),
        layout: Some(&pipeline_layout),
        vertex: VertexState {
            module: &shader,
            entry_point: Some("vs_main"),
            buffers: &[wgpu::VertexBufferLayout {
                array_stride: std::mem::size_of::<SpriteVertex>() as wgpu::BufferAddress,
                step_mode: wgpu::VertexStepMode::Vertex,
                attributes: &vertex_attr_array![0 => Float32x2, 1 => Float32x2],
            }],
            compilation_options: wgpu::PipelineCompilationOptions::default(),
        },
        fragment: Some(FragmentState {
            module: &shader,
            entry_point: Some("fs_main"),
            targets: &[Some(ColorTargetState {
                format: surface_format,
                blend: Some(wgpu::BlendState::REPLACE),
                write_mask: ColorWrites::ALL,
            })],
            compilation_options: wgpu::PipelineCompilationOptions::default(),
        }),
        primitive: PrimitiveState::default(),
        depth_stencil: None,
        multisample: MultisampleState::default(),
        multiview_mask: None,
        cache: None,
    });

    CompositePipeline {
        pipeline,
        bind_group_layout,
        vertex_buffer,
    }
}

fn choose_present_mode(modes: &[PresentMode], vsync: bool) -> PresentMode {
    if vsync {
        modes
            .iter()
            .copied()
            .find(|mode| matches!(mode, PresentMode::Fifo | PresentMode::FifoRelaxed))
            .unwrap_or(PresentMode::Fifo)
    } else {
        modes
            .iter()
            .copied()
            .find(|mode| matches!(mode, PresentMode::Immediate | PresentMode::Mailbox))
            .unwrap_or(PresentMode::Immediate)
    }
}

fn choose_alpha_mode(modes: &[CompositeAlphaMode]) -> CompositeAlphaMode {
    modes
        .iter()
        .copied()
        .find(|mode| matches!(mode, CompositeAlphaMode::Auto))
        .unwrap_or_else(|| modes.first().copied().unwrap_or(CompositeAlphaMode::Opaque))
}

fn create_shape_pipeline(device: &wgpu::Device, surface_format: TextureFormat) -> ShapePipeline {
    let shader = device.create_shader_module(ShaderModuleDescriptor {
        label: Some("shape-shader"),
        source: ShaderSource::Wgsl(include_str!("shape.wgsl").into()),
    });

    let bind_group_layout = device.create_bind_group_layout(&BindGroupLayoutDescriptor {
        label: Some("shape-bind-group-layout"),
        entries: &[BindGroupLayoutEntry {
            binding: 0,
            visibility: wgpu::ShaderStages::VERTEX_FRAGMENT,
            ty: BindingType::Buffer {
                ty: BufferBindingType::Uniform,
                has_dynamic_offset: false,
                min_binding_size: std::num::NonZeroU64::new(
                    std::mem::size_of::<ShapeUniforms>() as u64
                ),
            },
            count: None,
        }],
    });

    let pipeline_layout = device.create_pipeline_layout(&PipelineLayoutDescriptor {
        label: Some("shape-pipeline-layout"),
        bind_group_layouts: &[&bind_group_layout],
        immediate_size: 0,
    });

    let uniform_alignment = device.limits().min_uniform_buffer_offset_alignment as u64;
    let uniform_size = std::mem::size_of::<ShapeUniforms>() as u64;
    let aligned_uniform_size = (uniform_size + uniform_alignment - 1) & !(uniform_alignment - 1);

    let uniform_buffer = device.create_buffer(&wgpu::BufferDescriptor {
        label: Some("shape-uniform-buffer"),
        size: aligned_uniform_size,
        usage: BufferUsages::UNIFORM | BufferUsages::COPY_DST,
        mapped_at_creation: false,
    });

    let pipeline = device.create_render_pipeline(&RenderPipelineDescriptor {
        label: Some("shape-pipeline"),
        layout: Some(&pipeline_layout),
        vertex: VertexState {
            module: &shader,
            entry_point: Some("vs_main"),
            buffers: &[wgpu::VertexBufferLayout {
                array_stride: std::mem::size_of::<ShapeVertex>() as wgpu::BufferAddress,
                step_mode: wgpu::VertexStepMode::Vertex,
                attributes: &vertex_attr_array![0 => Float32x2],
            }],
            compilation_options: wgpu::PipelineCompilationOptions::default(),
        },
        fragment: Some(FragmentState {
            module: &shader,
            entry_point: Some("fs_main"),
            targets: &[
                Some(ColorTargetState {
                format: surface_format,
                blend: Some(wgpu::BlendState::ALPHA_BLENDING),
                write_mask: ColorWrites::ALL,
                }),
                // Occlusion target (R8)
                Some(ColorTargetState {
                    format: TextureFormat::R8Unorm,
                    blend: Some(wgpu::BlendState::REPLACE),
                    write_mask: ColorWrites::ALL,
                }),
            ],
            compilation_options: wgpu::PipelineCompilationOptions::default(),
        }),
        primitive: PrimitiveState {
            topology: wgpu::PrimitiveTopology::TriangleList,
            strip_index_format: None,
            front_face: wgpu::FrontFace::Ccw,
            cull_mode: None,
            unclipped_depth: false,
            polygon_mode: wgpu::PolygonMode::Fill,
            conservative: false,
        },
        depth_stencil: None,
        multisample: MultisampleState::default(),
        multiview_mask: None,
        cache: None,
    });

    ShapePipeline {
        pipeline,
        bind_group_layout,
        uniform_buffer,
        uniform_alignment,
    }
}
